{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assignment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Crawling News from Times of India Website"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Steps to be followed:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Load all libraries\n",
    "- Using BeautifulSoup library fetch all article links and prepare dataframe from it.Here, i have used times of india website and business category.\n",
    "- Now, download Online News Popularity  dataset from UCI repository for predicting the virality of news article.\n",
    "- Preprocess the dataset.\n",
    "- Train a Model.here, Random forest is used as a machine learning algorithm.\n",
    "- For predicting the virality of news we convert the crawled news into the format of our prediction model.\n",
    "- We extract some useful features from text and append all the features to make dataframe.\n",
    "- Use above dataframe for predicitng virality of news using our trained model.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "from newspaper import Article  \n",
    "import csv \n",
    "from nltk.tokenize import word_tokenize \n",
    "from nltk.corpus import stopwords\n",
    "stopwords=set(stopwords.words('english'))\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = \"https://timesofindia.indiatimes.com/business\"\n",
    "r = requests.get(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" Prepare soup for getting the links of all articles in business category\"\"\"\n",
    "soup = BeautifulSoup(r.content, 'html5lib') \n",
    "table = soup.findAll('a', attrs = {'class':'w_img'}) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "news=[]\n",
    "for row in table: \n",
    "    if not row['href'].startswith('http'):\n",
    "        news.append('https://timesofindia.indiatimes.com'+row['href'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "news_data=[]\n",
    "\"\"\" Download all news artcles and append it to the news_data list\"\"\"\n",
    "for i in news:\n",
    "    article = Article(i, language=\"en\")\n",
    "    try:\n",
    "        article.download()\n",
    "    except ArticleException:\n",
    "        continue\n",
    "    article.download() \n",
    "    article.parse() \n",
    "    article.nlp() \n",
    "    data={}\n",
    "    data['Title']=article.title\n",
    "    data['Text']=article.text\n",
    "    data['Summary']=article.summary\n",
    "    data['Keywords']=article.keywords\n",
    "    news_data.append(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Title</th>\n",
       "      <th>Text</th>\n",
       "      <th>Summary</th>\n",
       "      <th>Keywords</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>sensex today: Sensex jumps 371 points to close...</td>\n",
       "      <td>(Representative image)\\n\\n(With agency inputs)...</td>\n",
       "      <td>(Representative image)(With agency inputs)Down...</td>\n",
       "      <td>[services, 9350, sensex, 32115, cent, jumps, t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Sensex up 743 points, Reliance gains 10% as Fa...</td>\n",
       "      <td>Apr 22, 2020, 07:46PM IST\\n\\nSource: ANI\\n\\nEq...</td>\n",
       "      <td>Apr 22, 2020, 07:46PM ISTSource: ANIEquity ben...</td>\n",
       "      <td>[stake, digital, jio, reliance, sensex, indust...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Sensex tanks over 1000 points as US oil prices...</td>\n",
       "      <td>Apr 21, 2020, 07:18PM IST\\n\\nSource: ANI\\n\\nEq...</td>\n",
       "      <td>Apr 21, 2020, 07:18PM ISTSource: ANIEquity ben...</td>\n",
       "      <td>[turned, zero, dollar, prices, sensex, indices...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>COVID-19 crisis: Sensex slides 469 points to c...</td>\n",
       "      <td>Apr 13, 2020, 06:27PM IST\\n\\nSource: Times Now...</td>\n",
       "      <td>Apr 13, 2020, 06:27PM ISTSource: Times NowIn t...</td>\n",
       "      <td>[slides, 30690, sensex, weighed, times, 469, o...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Sensex up by 2,100 points, Nifty above 8,700-mark</td>\n",
       "      <td>Apr 07, 2020, 03:30PM IST\\n\\nSource: Times Now...</td>\n",
       "      <td>Apr 07, 2020, 03:30PM ISTSource: Times NowGood...</td>\n",
       "      <td>[8700mark, sensex, times, trading, surged, tra...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               Title  \\\n",
       "0  sensex today: Sensex jumps 371 points to close...   \n",
       "1  Sensex up 743 points, Reliance gains 10% as Fa...   \n",
       "2  Sensex tanks over 1000 points as US oil prices...   \n",
       "3  COVID-19 crisis: Sensex slides 469 points to c...   \n",
       "4  Sensex up by 2,100 points, Nifty above 8,700-mark   \n",
       "\n",
       "                                                Text  \\\n",
       "0  (Representative image)\\n\\n(With agency inputs)...   \n",
       "1  Apr 22, 2020, 07:46PM IST\\n\\nSource: ANI\\n\\nEq...   \n",
       "2  Apr 21, 2020, 07:18PM IST\\n\\nSource: ANI\\n\\nEq...   \n",
       "3  Apr 13, 2020, 06:27PM IST\\n\\nSource: Times Now...   \n",
       "4  Apr 07, 2020, 03:30PM IST\\n\\nSource: Times Now...   \n",
       "\n",
       "                                             Summary  \\\n",
       "0  (Representative image)(With agency inputs)Down...   \n",
       "1  Apr 22, 2020, 07:46PM ISTSource: ANIEquity ben...   \n",
       "2  Apr 21, 2020, 07:18PM ISTSource: ANIEquity ben...   \n",
       "3  Apr 13, 2020, 06:27PM ISTSource: Times NowIn t...   \n",
       "4  Apr 07, 2020, 03:30PM ISTSource: Times NowGood...   \n",
       "\n",
       "                                            Keywords  \n",
       "0  [services, 9350, sensex, 32115, cent, jumps, t...  \n",
       "1  [stake, digital, jio, reliance, sensex, indust...  \n",
       "2  [turned, zero, dollar, prices, sensex, indices...  \n",
       "3  [slides, 30690, sensex, weighed, times, 469, o...  \n",
       "4  [8700mark, sensex, times, trading, surged, tra...  "
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df=pd.DataFrame(news_data)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(38, 4)"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False])"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "equal_column = np.where(df[\"Text\"] == df[\"Summary\"], True, False)\n",
    "\n",
    "equal_column"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prediction of virality of news"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Dataset is downloaded from UCI repository for training the model. Random forest is selected as a machine learning algorithm as it is easy to use and flexible."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1=pd.read_csv(\"OnlineNewsPopularity.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>url</th>\n",
       "      <th>timedelta</th>\n",
       "      <th>n_tokens_title</th>\n",
       "      <th>n_tokens_content</th>\n",
       "      <th>n_unique_tokens</th>\n",
       "      <th>n_non_stop_words</th>\n",
       "      <th>n_non_stop_unique_tokens</th>\n",
       "      <th>num_hrefs</th>\n",
       "      <th>num_self_hrefs</th>\n",
       "      <th>num_imgs</th>\n",
       "      <th>...</th>\n",
       "      <th>min_positive_polarity</th>\n",
       "      <th>max_positive_polarity</th>\n",
       "      <th>avg_negative_polarity</th>\n",
       "      <th>min_negative_polarity</th>\n",
       "      <th>max_negative_polarity</th>\n",
       "      <th>title_subjectivity</th>\n",
       "      <th>title_sentiment_polarity</th>\n",
       "      <th>abs_title_subjectivity</th>\n",
       "      <th>abs_title_sentiment_polarity</th>\n",
       "      <th>shares</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>http://mashable.com/2013/01/07/amazon-instant-...</td>\n",
       "      <td>731.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>219.0</td>\n",
       "      <td>0.663594</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.815385</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>0.7</td>\n",
       "      <td>-0.350000</td>\n",
       "      <td>-0.600</td>\n",
       "      <td>-0.200000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>-0.187500</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.187500</td>\n",
       "      <td>593</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>http://mashable.com/2013/01/07/ap-samsung-spon...</td>\n",
       "      <td>731.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>255.0</td>\n",
       "      <td>0.604743</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.791946</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.033333</td>\n",
       "      <td>0.7</td>\n",
       "      <td>-0.118750</td>\n",
       "      <td>-0.125</td>\n",
       "      <td>-0.100000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>711</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>http://mashable.com/2013/01/07/apple-40-billio...</td>\n",
       "      <td>731.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>211.0</td>\n",
       "      <td>0.575130</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.663866</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.466667</td>\n",
       "      <td>-0.800</td>\n",
       "      <td>-0.133333</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>http://mashable.com/2013/01/07/astronaut-notre...</td>\n",
       "      <td>731.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>531.0</td>\n",
       "      <td>0.503788</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.665635</td>\n",
       "      <td>9.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.136364</td>\n",
       "      <td>0.8</td>\n",
       "      <td>-0.369697</td>\n",
       "      <td>-0.600</td>\n",
       "      <td>-0.166667</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>http://mashable.com/2013/01/07/att-u-verse-apps/</td>\n",
       "      <td>731.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>1072.0</td>\n",
       "      <td>0.415646</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.540890</td>\n",
       "      <td>19.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.033333</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.220192</td>\n",
       "      <td>-0.500</td>\n",
       "      <td>-0.050000</td>\n",
       "      <td>0.454545</td>\n",
       "      <td>0.136364</td>\n",
       "      <td>0.045455</td>\n",
       "      <td>0.136364</td>\n",
       "      <td>505</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 61 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 url   timedelta  \\\n",
       "0  http://mashable.com/2013/01/07/amazon-instant-...       731.0   \n",
       "1  http://mashable.com/2013/01/07/ap-samsung-spon...       731.0   \n",
       "2  http://mashable.com/2013/01/07/apple-40-billio...       731.0   \n",
       "3  http://mashable.com/2013/01/07/astronaut-notre...       731.0   \n",
       "4   http://mashable.com/2013/01/07/att-u-verse-apps/       731.0   \n",
       "\n",
       "    n_tokens_title   n_tokens_content   n_unique_tokens   n_non_stop_words  \\\n",
       "0             12.0              219.0          0.663594                1.0   \n",
       "1              9.0              255.0          0.604743                1.0   \n",
       "2              9.0              211.0          0.575130                1.0   \n",
       "3              9.0              531.0          0.503788                1.0   \n",
       "4             13.0             1072.0          0.415646                1.0   \n",
       "\n",
       "    n_non_stop_unique_tokens   num_hrefs   num_self_hrefs   num_imgs  ...  \\\n",
       "0                   0.815385         4.0              2.0        1.0  ...   \n",
       "1                   0.791946         3.0              1.0        1.0  ...   \n",
       "2                   0.663866         3.0              1.0        1.0  ...   \n",
       "3                   0.665635         9.0              0.0        1.0  ...   \n",
       "4                   0.540890        19.0             19.0       20.0  ...   \n",
       "\n",
       "    min_positive_polarity   max_positive_polarity   avg_negative_polarity  \\\n",
       "0                0.100000                     0.7               -0.350000   \n",
       "1                0.033333                     0.7               -0.118750   \n",
       "2                0.100000                     1.0               -0.466667   \n",
       "3                0.136364                     0.8               -0.369697   \n",
       "4                0.033333                     1.0               -0.220192   \n",
       "\n",
       "    min_negative_polarity   max_negative_polarity   title_subjectivity  \\\n",
       "0                  -0.600               -0.200000             0.500000   \n",
       "1                  -0.125               -0.100000             0.000000   \n",
       "2                  -0.800               -0.133333             0.000000   \n",
       "3                  -0.600               -0.166667             0.000000   \n",
       "4                  -0.500               -0.050000             0.454545   \n",
       "\n",
       "    title_sentiment_polarity   abs_title_subjectivity  \\\n",
       "0                  -0.187500                 0.000000   \n",
       "1                   0.000000                 0.500000   \n",
       "2                   0.000000                 0.500000   \n",
       "3                   0.000000                 0.500000   \n",
       "4                   0.136364                 0.045455   \n",
       "\n",
       "    abs_title_sentiment_polarity   shares  \n",
       "0                       0.187500      593  \n",
       "1                       0.000000      711  \n",
       "2                       0.000000     1500  \n",
       "3                       0.000000     1200  \n",
       "4                       0.136364      505  \n",
       "\n",
       "[5 rows x 61 columns]"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['url', ' timedelta', ' n_tokens_title', ' n_tokens_content',\n",
       "       ' n_unique_tokens', ' n_non_stop_words', ' n_non_stop_unique_tokens',\n",
       "       ' num_hrefs', ' num_self_hrefs', ' num_imgs', ' num_videos',\n",
       "       ' average_token_length', ' num_keywords', ' data_channel_is_lifestyle',\n",
       "       ' data_channel_is_entertainment', ' data_channel_is_bus',\n",
       "       ' data_channel_is_socmed', ' data_channel_is_tech',\n",
       "       ' data_channel_is_world', ' kw_min_min', ' kw_max_min', ' kw_avg_min',\n",
       "       ' kw_min_max', ' kw_max_max', ' kw_avg_max', ' kw_min_avg',\n",
       "       ' kw_max_avg', ' kw_avg_avg', ' self_reference_min_shares',\n",
       "       ' self_reference_max_shares', ' self_reference_avg_sharess',\n",
       "       ' weekday_is_monday', ' weekday_is_tuesday', ' weekday_is_wednesday',\n",
       "       ' weekday_is_thursday', ' weekday_is_friday', ' weekday_is_saturday',\n",
       "       ' weekday_is_sunday', ' is_weekend', ' LDA_00', ' LDA_01', ' LDA_02',\n",
       "       ' LDA_03', ' LDA_04', ' global_subjectivity',\n",
       "       ' global_sentiment_polarity', ' global_rate_positive_words',\n",
       "       ' global_rate_negative_words', ' rate_positive_words',\n",
       "       ' rate_negative_words', ' avg_positive_polarity',\n",
       "       ' min_positive_polarity', ' max_positive_polarity',\n",
       "       ' avg_negative_polarity', ' min_negative_polarity',\n",
       "       ' max_negative_polarity', ' title_subjectivity',\n",
       "       ' title_sentiment_polarity', ' abs_title_subjectivity',\n",
       "       ' abs_title_sentiment_polarity', ' shares'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" split the dataset into test and train \"\"\"\n",
    "x_train, x_test = train_test_split(df1, test_size=0.20, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" drop all un necessary columns \"\"\"\n",
    "x_train1 = x_train.drop(['url',' shares', ' timedelta', ' LDA_00',' LDA_01',' LDA_02',' LDA_03',' LDA_04',' num_self_hrefs', ' kw_min_min', ' kw_max_min', ' kw_avg_min',' kw_min_max',' kw_max_max',' kw_avg_max',' kw_min_avg',' kw_max_avg',' kw_avg_avg',' self_reference_min_shares',' self_reference_max_shares',' self_reference_avg_sharess',' rate_positive_words',' rate_negative_words',' abs_title_subjectivity',' abs_title_sentiment_polarity'], axis=1)\n",
    "y_train = x_train[' shares']\n",
    "\n",
    "x_test1 = x_test.drop(['url',' shares', ' timedelta', ' LDA_00',' LDA_01',' LDA_02',' LDA_03',' LDA_04',' num_self_hrefs', ' kw_min_min', ' kw_max_min', ' kw_avg_min',' kw_min_max',' kw_max_max',' kw_avg_max',' kw_min_avg',' kw_max_avg',' kw_avg_avg',' self_reference_min_shares',' self_reference_max_shares',' self_reference_avg_sharess',' rate_positive_words',' rate_negative_words',' abs_title_subjectivity',' abs_title_sentiment_polarity'], axis=1)\n",
    "y_test = x_test[' shares']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/nupur/anaconda3/lib/python3.6/site-packages/sklearn/ensemble/forest.py:245: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomForestRegressor(bootstrap=True, criterion='mse', max_depth=None,\n",
       "                      max_features='auto', max_leaf_nodes=None,\n",
       "                      min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                      min_samples_leaf=1, min_samples_split=2,\n",
       "                      min_weight_fraction_leaf=0.0, n_estimators=10,\n",
       "                      n_jobs=None, oob_score=False, random_state=42, verbose=0,\n",
       "                      warm_start=False)"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = RandomForestRegressor(random_state=42)\n",
    "clf.fit(x_train1, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_shares = pd.DataFrame(clf.predict(x_train1),list(y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Actual shares</th>\n",
       "      <th>Predicted shares</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>16100</td>\n",
       "      <td>11492.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>508</td>\n",
       "      <td>1334.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1300</td>\n",
       "      <td>1280.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3100</td>\n",
       "      <td>2940.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6900</td>\n",
       "      <td>5960.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Actual shares  Predicted shares\n",
       "0          16100           11492.9\n",
       "1            508            1334.8\n",
       "2           1300            1280.0\n",
       "3           3100            2940.0\n",
       "4           6900            5960.0"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_shares.reset_index(level=0, inplace=True)\n",
    "df_shares1 = df_shares.rename(index=str, columns={\"index\": \"Actual shares\", 0: \"Predicted shares\"})\n",
    "df_shares1.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extracting useful features to convert crawled news into format of our prediction model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Features that we extracting are:\n",
    "a. No. of words in title\n",
    "\n",
    "b. No. of words in content(news article)\n",
    "\n",
    "c. Rate of unique tokens\n",
    "\n",
    "d. Rate of non-stop words\n",
    "\n",
    "e. Rate of non-stop unique words\n",
    "\n",
    "f. No. of URL’s present in content\n",
    "\n",
    "g. No. of Images in content\n",
    "\n",
    "h. No. of Videos in content\n",
    "\n",
    "i. Average word length\n",
    "\n",
    "j. No. of unique keywords\n",
    "\n",
    "k. type of data channel: lifestyle, entertainment, business, technology, social media, world\n",
    "\n",
    "l. day of week\n",
    "\n",
    "m. Subjectivity\n",
    "\n",
    "n. Sentiment polarity\n",
    "\n",
    "o. Rate of negative words\n",
    "\n",
    "p. Rate of Positive words\n",
    "\n",
    "q. Average Negative polarity\n",
    "\n",
    "r. Average Positive Polarity\n",
    "\n",
    "s. Minimum Positive polarity\n",
    "\n",
    "t. Maximum Positive Polarity\n",
    "\n",
    "u. Maximum Negative Polarity\n",
    "\n",
    "v. Minimum Negative Polarity\n",
    "\n",
    "w. Title Subjectivity\n",
    "\n",
    "x. Title Sentiment Polarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rate_nonstop(words):\n",
    "    words=tokenize(words)\n",
    "    filtered_sentence = [w for w in words if not w in stopwords]\n",
    "    rate_nonstop=len(filtered_sentence)/len(words)\n",
    "    no_order = list(set(filtered_sentence))\n",
    "    rate_unique_nonstop=len(no_order)/len(words)\n",
    "    return rate_nonstop,rate_unique_nonstop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rate_unique(words):\n",
    "    words=tokenize(words)\n",
    "    no_order = list(set(words))\n",
    "    rate_unique=len(no_order)/len(words)\n",
    "    return rate_unique"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datefinder\n",
    "import datetime  \n",
    "from textblob import TextBlob\n",
    "from datetime import date \n",
    "def day(article_text):\n",
    "    article=article_text\n",
    "    if len(list(datefinder.find_dates(article)))>0:\n",
    "        date=str(list(datefinder.find_dates(article))[0])\n",
    "        date=date.split()\n",
    "        date=date[0]\n",
    "        year, month, day = date.split('-')     \n",
    "        day_name = datetime.date(int(year), int(month), int(day)) \n",
    "        return day_name.strftime(\"%A\")\n",
    "    return \"Monday\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "def avg_token(words):\n",
    "    words=tokenize(words)\n",
    "    length=[]\n",
    "    for i in words:\n",
    "        length.append(len(i))\n",
    "    return np.average(length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize(text):\n",
    "    text=text\n",
    "    return word_tokenize(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "pos_words=[]\n",
    "neg_words=[]\n",
    "def polar(words):\n",
    "    all_tokens=tokenize(words)\n",
    "    for i in all_tokens:\n",
    "        analysis=TextBlob(i)\n",
    "        polarity=analysis.sentiment.polarity\n",
    "        if polarity>0:\n",
    "            pos_words.append(i)\n",
    "        if polarity<0:\n",
    "            neg_words.append(i)\n",
    "    return pos_words,neg_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rates(words):\n",
    "    words=polar(words)\n",
    "    pos=words[0]\n",
    "    neg=words[1]\n",
    "    all_words=words\n",
    "    global_rate_positive_words=(len(pos)/len(all_words))/100\n",
    "    global_rate_negative_words=(len(neg)/len(all_words))/100\n",
    "    pol_pos=[]\n",
    "    pol_neg=[]\n",
    "    for i in pos:\n",
    "        analysis=TextBlob(i)\n",
    "        pol_pos.append(analysis.sentiment.polarity)\n",
    "        avg_positive_polarity=analysis.sentiment.polarity\n",
    "    for j in neg:\n",
    "        analysis2=TextBlob(j)\n",
    "        pol_neg.append(analysis2.sentiment.polarity)\n",
    "        avg_negative_polarity=analysis2.sentiment.polarity\n",
    "    min_positive_polarity=min(pol_pos)\n",
    "    max_positive_polarity=max(pol_pos)\n",
    "    min_negative_polarity=min(pol_neg)\n",
    "    max_negative_polarity=max(pol_neg)\n",
    "    avg_positive_polarity=np.average(pol_pos)\n",
    "    avg_negative_polarity=np.average(pol_neg)\n",
    "    return global_rate_positive_words,global_rate_negative_words,avg_positive_polarity,min_positive_polarity,max_positive_polarity,avg_negative_polarity,min_negative_polarity,max_negative_polarity\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_final=[]\n",
    "for i in news:\n",
    "    all_info={}\n",
    "    article = Article(i, language=\"en\")\n",
    "    article.download() \n",
    "    article.parse()\n",
    "    analysis=TextBlob(article.text)\n",
    "    polarity=analysis.sentiment.polarity\n",
    "    title_analysis=TextBlob(article.title)\n",
    "    all_info['text']=article.text\n",
    "    all_info['n_tokens_title']=len(tokenize(article.title))\n",
    "    all_info['n_tokens_content']=len(tokenize(article.text))\n",
    "    all_info['n_unique_tokens']=rate_unique(article.text)\n",
    "    all_info['n_non_stop_words']=rate_nonstop(article.text)[0]\n",
    "    all_info['n_non_stop_unique_tokens']=rate_nonstop(article.text)[1]\n",
    "    all_info['num_hrefs']=article.html.count(\"https://timesofindia.indiatimes.com\")\n",
    "    all_info['num_imgs']=len(article.images)\n",
    "    all_info['num_videos']=len(article.movies)\n",
    "    all_info['average_token_length']=avg_token(article.text)\n",
    "    all_info['num_keywords']=len(article.keywords)\n",
    "    \n",
    "    if \"life-style\" in article.url:\n",
    "        all_info['data_channel_is_lifestyle']=1\n",
    "    else:\n",
    "        all_info['data_channel_is_lifestyle']=0\n",
    "    if \"etimes\" in article.url:\n",
    "        all_info['data_channel_is_entertainment']=1\n",
    "    else:\n",
    "        all_info['data_channel_is_entertainment']=0\n",
    "    if \"business\" in article.url:\n",
    "        all_info['data_channel_is_bus']=1\n",
    "    else:\n",
    "        all_info['data_channel_is_bus']=0\n",
    "    if \"social media\" or \"facebook\" or \"whatsapp\" in article.text.lower():\n",
    "        data_channel_is_socmed=1\n",
    "        data_channel_is_tech=0\n",
    "        data_channel_is_world=0\n",
    "    else:\n",
    "        data_channel_is_socmed=0\n",
    "    if (\"technology\" or \"tech\" in article.text.lower()) or (\"technology\" or \"tech\" in article.url):\n",
    "        data_channel_is_tech=1\n",
    "        data_channel_is_socmed=0\n",
    "        data_channel_is_world=0\n",
    "    else:\n",
    "        data_channel_is_tech=0\n",
    "    if \"world\" in article.url:\n",
    "        data_channel_is_world=1\n",
    "        data_channel_is_tech=0\n",
    "        data_channel_is_socmed=0\n",
    "    else:\n",
    "        data_channel_is_world=0\n",
    "        \n",
    "    all_info['data_channel_is_socmed']=data_channel_is_socmed\n",
    "    all_info['data_channel_is_tech']=data_channel_is_tech\n",
    "    all_info['data_channel_is_world']=data_channel_is_world\n",
    "    \n",
    "    if day(i)==\"Monday\":\n",
    "        all_info['weekday_is_monday']=1\n",
    "    else:\n",
    "        all_info['weekday_is_monday']=0\n",
    "    if day(i)==\"Tuesday\":\n",
    "        all_info['weekday_is_tuesday']=1\n",
    "    else:\n",
    "        all_info['weekday_is_tuesday']=0\n",
    "    if day(i)==\"Wednesday\":\n",
    "        all_info['weekday_is_wednesday']=1\n",
    "    else:\n",
    "        all_info['weekday_is_wednesday']=0\n",
    "    if day(i)==\"Thursday\":\n",
    "        all_info['weekday_is_thursday']=1\n",
    "    else:\n",
    "        all_info['weekday_is_thursday']=0\n",
    "    if day(i)==\"Friday\":\n",
    "        all_info['weekday_is_friday']=1\n",
    "    else:\n",
    "        all_info['weekday_is_friday']=0\n",
    "    if day(i)==\"Saturday\":\n",
    "        all_info['weekday_is_saturday']=1\n",
    "        all_info['is_weekend']=1\n",
    "    else:\n",
    "        all_info['weekday_is_saturday']=0\n",
    "    if day(i)==\"Sunday\":\n",
    "        all_info['weekday_is_sunday']=1\n",
    "        all_info['is_weekend']=1\n",
    "    else:\n",
    "        all_info['weekday_is_sunday']=0\n",
    "        all_info['is_weekend']=0\n",
    "        \n",
    "    all_info['global_subjectivity']=analysis.sentiment.subjectivity\n",
    "    all_info['global_sentiment_polarity']=analysis.sentiment.polarity\n",
    "    all_info['global_rate_positive_words']=rates(article.text)[0]\n",
    "    all_info['global_rate_negative_words']=rates(article.text)[1]\n",
    "    all_info['avg_positive_polarity']=rates(article.text)[2]\n",
    "    all_info['min_positive_polarity']=rates(article.text)[3]\n",
    "    all_info['max_positive_polarity']=rates(article.text)[4]\n",
    "    all_info['avg_negative_polarity']=rates(article.text)[5]\n",
    "    all_info['min_negative_polarity']=rates(article.text)[6]\n",
    "    all_info['max_negative_polarity']=rates(article.text)[7]    \n",
    "    all_info['title_subjectivity']=title_analysis.sentiment.subjectivity\n",
    "    all_info['title_sentiment_polarity']=title_analysis.sentiment.polarity\n",
    "    df_final.append(all_info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>n_tokens_title</th>\n",
       "      <th>n_tokens_content</th>\n",
       "      <th>n_unique_tokens</th>\n",
       "      <th>n_non_stop_words</th>\n",
       "      <th>n_non_stop_unique_tokens</th>\n",
       "      <th>num_hrefs</th>\n",
       "      <th>num_imgs</th>\n",
       "      <th>num_videos</th>\n",
       "      <th>average_token_length</th>\n",
       "      <th>...</th>\n",
       "      <th>global_rate_positive_words</th>\n",
       "      <th>global_rate_negative_words</th>\n",
       "      <th>avg_positive_polarity</th>\n",
       "      <th>min_positive_polarity</th>\n",
       "      <th>max_positive_polarity</th>\n",
       "      <th>avg_negative_polarity</th>\n",
       "      <th>min_negative_polarity</th>\n",
       "      <th>max_negative_polarity</th>\n",
       "      <th>title_subjectivity</th>\n",
       "      <th>title_sentiment_polarity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>(Representative image)\\n\\n(With agency inputs)...</td>\n",
       "      <td>16</td>\n",
       "      <td>364</td>\n",
       "      <td>0.634615</td>\n",
       "      <td>0.747253</td>\n",
       "      <td>0.546703</td>\n",
       "      <td>319</td>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "      <td>4.648352</td>\n",
       "      <td>...</td>\n",
       "      <td>0.050</td>\n",
       "      <td>0.11</td>\n",
       "      <td>0.331364</td>\n",
       "      <td>0.136364</td>\n",
       "      <td>0.6</td>\n",
       "      <td>-0.274675</td>\n",
       "      <td>-0.7</td>\n",
       "      <td>-0.071429</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Apr 22, 2020, 07:46PM IST\\n\\nSource: ANI\\n\\nEq...</td>\n",
       "      <td>15</td>\n",
       "      <td>179</td>\n",
       "      <td>0.614525</td>\n",
       "      <td>0.754190</td>\n",
       "      <td>0.508380</td>\n",
       "      <td>185</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>4.089385</td>\n",
       "      <td>...</td>\n",
       "      <td>0.415</td>\n",
       "      <td>0.45</td>\n",
       "      <td>0.329877</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>0.6</td>\n",
       "      <td>-0.269909</td>\n",
       "      <td>-0.7</td>\n",
       "      <td>-0.071429</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Apr 21, 2020, 07:18PM IST\\n\\nSource: ANI\\n\\nEq...</td>\n",
       "      <td>15</td>\n",
       "      <td>200</td>\n",
       "      <td>0.685000</td>\n",
       "      <td>0.720000</td>\n",
       "      <td>0.560000</td>\n",
       "      <td>185</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>4.260000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.530</td>\n",
       "      <td>0.53</td>\n",
       "      <td>0.330537</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>0.6</td>\n",
       "      <td>-0.271731</td>\n",
       "      <td>-0.7</td>\n",
       "      <td>-0.071429</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Apr 13, 2020, 06:27PM IST\\n\\nSource: Times Now...</td>\n",
       "      <td>18</td>\n",
       "      <td>81</td>\n",
       "      <td>0.814815</td>\n",
       "      <td>0.753086</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>185</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>4.530864</td>\n",
       "      <td>...</td>\n",
       "      <td>0.605</td>\n",
       "      <td>0.68</td>\n",
       "      <td>0.330155</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>0.6</td>\n",
       "      <td>-0.272502</td>\n",
       "      <td>-0.7</td>\n",
       "      <td>-0.071429</td>\n",
       "      <td>0.288889</td>\n",
       "      <td>-0.155556</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Apr 07, 2020, 03:30PM IST\\n\\nSource: Times Now...</td>\n",
       "      <td>9</td>\n",
       "      <td>69</td>\n",
       "      <td>0.826087</td>\n",
       "      <td>0.768116</td>\n",
       "      <td>0.681159</td>\n",
       "      <td>185</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>4.666667</td>\n",
       "      <td>...</td>\n",
       "      <td>0.655</td>\n",
       "      <td>0.68</td>\n",
       "      <td>0.325492</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>0.7</td>\n",
       "      <td>-0.272502</td>\n",
       "      <td>-0.7</td>\n",
       "      <td>-0.071429</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 37 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  n_tokens_title  \\\n",
       "0  (Representative image)\\n\\n(With agency inputs)...              16   \n",
       "1  Apr 22, 2020, 07:46PM IST\\n\\nSource: ANI\\n\\nEq...              15   \n",
       "2  Apr 21, 2020, 07:18PM IST\\n\\nSource: ANI\\n\\nEq...              15   \n",
       "3  Apr 13, 2020, 06:27PM IST\\n\\nSource: Times Now...              18   \n",
       "4  Apr 07, 2020, 03:30PM IST\\n\\nSource: Times Now...               9   \n",
       "\n",
       "   n_tokens_content  n_unique_tokens  n_non_stop_words  \\\n",
       "0               364         0.634615          0.747253   \n",
       "1               179         0.614525          0.754190   \n",
       "2               200         0.685000          0.720000   \n",
       "3                81         0.814815          0.753086   \n",
       "4                69         0.826087          0.768116   \n",
       "\n",
       "   n_non_stop_unique_tokens  num_hrefs  num_imgs  num_videos  \\\n",
       "0                  0.546703        319        11           0   \n",
       "1                  0.508380        185         9           0   \n",
       "2                  0.560000        185         9           0   \n",
       "3                  0.666667        185         9           0   \n",
       "4                  0.681159        185         9           0   \n",
       "\n",
       "   average_token_length  ...  global_rate_positive_words  \\\n",
       "0              4.648352  ...                       0.050   \n",
       "1              4.089385  ...                       0.415   \n",
       "2              4.260000  ...                       0.530   \n",
       "3              4.530864  ...                       0.605   \n",
       "4              4.666667  ...                       0.655   \n",
       "\n",
       "   global_rate_negative_words  avg_positive_polarity  min_positive_polarity  \\\n",
       "0                        0.11               0.331364               0.136364   \n",
       "1                        0.45               0.329877               0.100000   \n",
       "2                        0.53               0.330537               0.100000   \n",
       "3                        0.68               0.330155               0.100000   \n",
       "4                        0.68               0.325492               0.100000   \n",
       "\n",
       "   max_positive_polarity  avg_negative_polarity  min_negative_polarity  \\\n",
       "0                    0.6              -0.274675                   -0.7   \n",
       "1                    0.6              -0.269909                   -0.7   \n",
       "2                    0.6              -0.271731                   -0.7   \n",
       "3                    0.6              -0.272502                   -0.7   \n",
       "4                    0.7              -0.272502                   -0.7   \n",
       "\n",
       "   max_negative_polarity  title_subjectivity  title_sentiment_polarity  \n",
       "0              -0.071429            0.100000                  0.000000  \n",
       "1              -0.071429            0.000000                  0.000000  \n",
       "2              -0.071429            0.000000                  0.000000  \n",
       "3              -0.071429            0.288889                 -0.155556  \n",
       "4              -0.071429            0.100000                  0.000000  \n",
       "\n",
       "[5 rows x 37 columns]"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_final1=pd.DataFrame(df_final)\n",
    "pred_test=df_final1.drop(['text'],axis=1)\n",
    "df_final1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>Virality</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>(Representative image)\\n\\n(With agency inputs)...</td>\n",
       "      <td>21990.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Apr 22, 2020, 07:46PM IST\\n\\nSource: ANI\\n\\nEq...</td>\n",
       "      <td>26910.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Apr 21, 2020, 07:18PM IST\\n\\nSource: ANI\\n\\nEq...</td>\n",
       "      <td>28830.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Apr 13, 2020, 06:27PM IST\\n\\nSource: Times Now...</td>\n",
       "      <td>27081.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Apr 07, 2020, 03:30PM IST\\n\\nSource: Times Now...</td>\n",
       "      <td>21080.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Apr 07, 2020, 02:58PM IST\\n\\nSource: ANI\\n\\nEq...</td>\n",
       "      <td>20470.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Apr 06, 2020, 03:24PM IST\\n\\nSource: ANI\\n\\nTh...</td>\n",
       "      <td>23620.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Apr 01, 2020, 10:20PM IST\\n\\nSource: ANI\\n\\nEq...</td>\n",
       "      <td>29775.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Apr 01, 2020, 03:26PM IST\\n\\nSource: ANI\\n\\nEq...</td>\n",
       "      <td>24460.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Apr 01, 2020, 02:38PM IST\\n\\nSource: TOI.in\\n\\...</td>\n",
       "      <td>34510.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Mar 31, 2020, 07:39PM IST\\n\\nSource: ANI\\n\\nEq...</td>\n",
       "      <td>22180.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>(File photo)\\n\\nMore on Covid-19\\n\\nDownload T...</td>\n",
       "      <td>26370.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Download The Times of India News App for Lates...</td>\n",
       "      <td>27710.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Delta Airlines planes grounded amid lockdown t...</td>\n",
       "      <td>18939.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>US President Donald Trump suspended certain ty...</td>\n",
       "      <td>21681.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>NEW DELHI: Indian tech-led startups attracted ...</td>\n",
       "      <td>4998.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>NEW DELHI: Home-grown regional language social...</td>\n",
       "      <td>54027.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>CHENNAI: Indian Institute of Technology (IIT) ...</td>\n",
       "      <td>10535.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>HYDERABAD: OncoSeek Bio Pvt Ltd, a start-up in...</td>\n",
       "      <td>8770.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>BEIJING/SHANGHAI: China's Inceptio Technology ...</td>\n",
       "      <td>11423.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>NEW DELHI: Bijak, a B2B platform for agricultu...</td>\n",
       "      <td>17200.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>(Representative image)\\n\\nDownload The Times o...</td>\n",
       "      <td>19190.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>THIRUVANANTHAPURAM: State-run Indian Institute...</td>\n",
       "      <td>14013.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>KIEV: The headquarters of Dmytro Voloshyn 's s...</td>\n",
       "      <td>7452.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>NEW DELHI: FieldFresh Foods Pvt Ltd on Wednesd...</td>\n",
       "      <td>14307.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>The nudge came in an email in early March from...</td>\n",
       "      <td>10179.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>BENGALURU: From screening, monitoring, diagnos...</td>\n",
       "      <td>8332.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>(File photo)\\n\\nMore on Covid-19\\n\\nDownload T...</td>\n",
       "      <td>22420.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>(Representative image)\\n\\nDownload The Times o...</td>\n",
       "      <td>23161.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>&lt;p&gt;Deepak Parekh (File photo)&lt;br&gt;&lt;/p&gt;\\n\\nMore ...</td>\n",
       "      <td>16672.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>(Representative image)\\n\\nDownload The Times o...</td>\n",
       "      <td>23450.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>(Representative image)\\n\\nDownload The Times o...</td>\n",
       "      <td>23030.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>(Representative image)\\n\\nDownload The Times o...</td>\n",
       "      <td>21466.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>Apr 28, 2020, 03:39PM IST\\n\\nSource: TNN\\n\\nBJ...</td>\n",
       "      <td>31990.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>Health workers and police officials are among ...</td>\n",
       "      <td>15030.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>Haryanvi dancer-singer Sapna Choudhary is all ...</td>\n",
       "      <td>13861.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>Apr 28, 2020, 12:14PM IST\\n\\nSource: Times Now...</td>\n",
       "      <td>28600.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>Apr 28, 2020, 12:22PM IST\\n\\nSource: TOI.in\\n\\...</td>\n",
       "      <td>37730.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 text  Virality\n",
       "0   (Representative image)\\n\\n(With agency inputs)...   21990.0\n",
       "1   Apr 22, 2020, 07:46PM IST\\n\\nSource: ANI\\n\\nEq...   26910.0\n",
       "2   Apr 21, 2020, 07:18PM IST\\n\\nSource: ANI\\n\\nEq...   28830.0\n",
       "3   Apr 13, 2020, 06:27PM IST\\n\\nSource: Times Now...   27081.9\n",
       "4   Apr 07, 2020, 03:30PM IST\\n\\nSource: Times Now...   21080.0\n",
       "5   Apr 07, 2020, 02:58PM IST\\n\\nSource: ANI\\n\\nEq...   20470.0\n",
       "6   Apr 06, 2020, 03:24PM IST\\n\\nSource: ANI\\n\\nTh...   23620.0\n",
       "7   Apr 01, 2020, 10:20PM IST\\n\\nSource: ANI\\n\\nEq...   29775.9\n",
       "8   Apr 01, 2020, 03:26PM IST\\n\\nSource: ANI\\n\\nEq...   24460.0\n",
       "9   Apr 01, 2020, 02:38PM IST\\n\\nSource: TOI.in\\n\\...   34510.0\n",
       "10  Mar 31, 2020, 07:39PM IST\\n\\nSource: ANI\\n\\nEq...   22180.0\n",
       "11  (File photo)\\n\\nMore on Covid-19\\n\\nDownload T...   26370.0\n",
       "12  Download The Times of India News App for Lates...   27710.0\n",
       "13  Delta Airlines planes grounded amid lockdown t...   18939.8\n",
       "14  US President Donald Trump suspended certain ty...   21681.9\n",
       "15  NEW DELHI: Indian tech-led startups attracted ...    4998.9\n",
       "16  NEW DELHI: Home-grown regional language social...   54027.6\n",
       "17  CHENNAI: Indian Institute of Technology (IIT) ...   10535.9\n",
       "18  HYDERABAD: OncoSeek Bio Pvt Ltd, a start-up in...    8770.0\n",
       "19  BEIJING/SHANGHAI: China's Inceptio Technology ...   11423.0\n",
       "20  NEW DELHI: Bijak, a B2B platform for agricultu...   17200.0\n",
       "21  (Representative image)\\n\\nDownload The Times o...   19190.6\n",
       "22  THIRUVANANTHAPURAM: State-run Indian Institute...   14013.0\n",
       "23  KIEV: The headquarters of Dmytro Voloshyn 's s...    7452.7\n",
       "24  NEW DELHI: FieldFresh Foods Pvt Ltd on Wednesd...   14307.6\n",
       "25  The nudge came in an email in early March from...   10179.5\n",
       "26  BENGALURU: From screening, monitoring, diagnos...    8332.8\n",
       "27  (File photo)\\n\\nMore on Covid-19\\n\\nDownload T...   22420.0\n",
       "28  (Representative image)\\n\\nDownload The Times o...   23161.7\n",
       "29  <p>Deepak Parekh (File photo)<br></p>\\n\\nMore ...   16672.7\n",
       "30  (Representative image)\\n\\nDownload The Times o...   23450.0\n",
       "31  (Representative image)\\n\\nDownload The Times o...   23030.0\n",
       "32  (Representative image)\\n\\nDownload The Times o...   21466.7\n",
       "33  Apr 28, 2020, 03:39PM IST\\n\\nSource: TNN\\n\\nBJ...   31990.0\n",
       "34  Health workers and police officials are among ...   15030.0\n",
       "35  Haryanvi dancer-singer Sapna Choudhary is all ...   13861.1\n",
       "36  Apr 28, 2020, 12:14PM IST\\n\\nSource: Times Now...   28600.0\n",
       "37  Apr 28, 2020, 12:22PM IST\\n\\nSource: TOI.in\\n\\...   37730.0"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_final2=pd.DataFrame(clf.predict(pred_test),df_final1['text'])\n",
    "df_final2.reset_index(level=0, inplace=True)\n",
    "df_final2 = df_final2.rename(index=str, columns={\"index\": \"News\", 0: \"Virality\"})\n",
    "df_final2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
